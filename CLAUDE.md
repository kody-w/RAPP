# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

RAPP (Rapid Agent Prototyping Platform/Pattern) is a flexible AI agent framework built on Azure Functions with OpenAI-compatible API integration. It features a modular agent architecture with persistent memory across sessions using Azure File Storage. The system supports multi-user conversations with user-specific and shared memory contexts, enabling rapid prototyping and deployment of AI agents for any use case. Works with Azure OpenAI, OpenAI, or any OpenAI-compatible endpoint.

**Deployment Options:**
- **Standalone Mode**: Direct API access via Azure Functions (REST endpoint) - Primary deployment pattern
- **Power Platform Integration**: Optional Microsoft 365 integration via Copilot Studio, Power Automate, Teams, and M365 Copilot

## Development Commands

### Running Locally

**Mac/Linux:**
```bash
./run.sh
```

**Windows:**
```powershell
.\run.ps1
```

The local API endpoint will be available at: `http://localhost:7071/api/businessinsightbot_function`

### Testing the API

**curl (Mac/Linux):**
```bash
curl -X POST http://localhost:7071/api/businessinsightbot_function \
  -H "Content-Type: application/json" \
  -d '{"user_input": "Hello", "conversation_history": []}'
```

**PowerShell (Windows):**
```powershell
Invoke-RestMethod -Uri "http://localhost:7071/api/businessinsightbot_function" `
  -Method Post `
  -Body '{"user_input": "Hello", "conversation_history": []}' `
  -ContentType "application/json"
```

### Environment Setup

- **Python version:** 3.11 (required for Azure Functions v4 compatibility)
- **Virtual environment:** `.venv/` (created automatically by setup scripts)
  ```bash
  # Activate virtual environment
  source .venv/bin/activate  # Mac/Linux
  .venv\Scripts\activate     # Windows
  ```
- **Dependencies:** Install with `pip install -r requirements.txt`
- **Configuration:** `local.settings.json` contains all Azure service credentials and settings (auto-generated by deployment script, never commit this file)

### Development Tools

**Checking logs:**
```bash
# View function logs in real-time
func start --verbose

# Check Azure Function App logs
az functionapp log tail --name YOUR_FUNCTION_APP --resource-group YOUR_RESOURCE_GROUP
```

**Local debugging:**
- Set breakpoints in VS Code with Azure Functions extension
- Use `logging.info()` and `logging.error()` for debug output
- Check `/tmp/agents` and `/tmp/multi_agents` for runtime-loaded agent files

## Architecture

### Full Stack Architecture

The complete solution spans multiple layers when deployed with Power Platform integration:

**User Interface Layer:**
- Microsoft 365 Copilot (M365 chat integration)
- Microsoft Teams (standalone bot or embedded)
- Web Interface (custom HTML/React applications)

**Conversation Layer:**
- Copilot Studio: Natural language processing, conversation management, user authentication
- Handles dialog flow, intent recognition, and context maintenance

**Integration Layer:**
- Power Automate: User context from Office 365, data transformation, error handling
- Connects Copilot Studio to Azure Functions
- Manages authentication and data flow between systems

**Processing Layer:**
- Azure Functions: Agent selection & routing, memory management, Azure OpenAI integration
- Core business logic and agent orchestration
- Stateless execution with persistent storage

**Agent Layer:**
- CRM Agents (Dynamics 365, Salesforce)
- Document Agents (SharePoint, OneDrive)
- Email Agents (Outlook integration)
- Calendar Agents (meeting management)
- Custom Agents (business-specific logic)

**Data Layer:**
- Azure Storage (agent memory and file storage)
- OpenAI-Compatible API (Azure OpenAI, OpenAI, or local models for AI processing)
- CRM Systems (business data)

### Core Components

**function_app.py (main entry point):**
- Single Azure Function HTTP trigger endpoint:
  - `businessinsightbot_function`: Main conversational endpoint
- `Assistant` class orchestrates the AI conversation flow (function_app.py:230)
- Dynamic agent loading from both local `agents/` folder and Azure File Storage (`agents/` and `multi_agents/` shares)
- GUID-based user context management with default GUID: `c0p110t0-aaaa-bbbb-cccc-123456789abc`
- Dual-response system: formatted markdown response + concise voice response (split by `|||VOICE|||` delimiter)
- Demo system: Scripted conversation flows triggered by specific phrases (function_app.py:364-701)

**Agent System:**
- All agents inherit from `BasicAgent` (agents/basic_agent.py)
- Agents define `name`, `metadata` (JSON schema for OpenAI function calling), and `perform(**kwargs)` method
- Built-in agents:
  - `ContextMemoryAgent`: Recalls conversation history (shared + user-specific memories)
  - `ManageMemoryAgent`: Stores facts, preferences, insights, and tasks to memory
  - `GithubAgentLibraryManager`: Manages agent library downloads and installations
  - `ScriptedDemoAgent`: Provides interactive demos and walkthroughs
- Custom agents can be added to `agents/` folder or uploaded to Azure File Storage
- Agent discovery is optimized via `agent_manifest.json` which caches metadata for faster loading (function_app.py:903-968)

**Agent Filtering (Per-User):**
- Users can enable/disable specific agents via `agent_config/{user_guid}/enabled_agents.json`
- Format: JSON array of agent filenames (e.g., `["context_memory_agent.py", "manage_memory_agent.py"]`)
- If no config exists, all agents are loaded by default
- Useful for limiting functionality per user or testing specific agents
- Configuration files can be managed directly in Azure File Storage

**Memory System:**
- Dual-layer memory: shared (all users) + user-specific (per GUID)
- Storage: Azure File Share via `AzureFileStorageManager` (utils/azure_file_storage.py)
- User context switching: Send a GUID as the first message or in `user_input` to load user-specific memory
- Memory trimming: Conversation history limited to last 20 messages to prevent memory overflow
- Shared memories stored in `shared_memories/memory.json`
- User-specific memories in `memory/{guid}/user_memory.json`

**Demo/Scripted Conversation System:**
- Demos are JSON files stored in Azure File Storage `demos/` directory
- Each demo defines `trigger_phrases` that activate the scripted conversation
- Demo data includes a `conversation_flow` array of steps
- State is extracted from conversation history (stateless design)
- Users can exit demos with "exit demo", "stop demo", "end demo", or "cancel demo"
- ScriptedDemoAgent (if loaded) handles canned responses for each step

### Request Flow

**Standalone Mode (Direct API):**
1. HTTP request → `businessinsightbot_function` endpoint
2. Load agents from local folder + Azure File Storage (with per-user filtering)
3. Create `Assistant` instance with user GUID (from request or default)
4. Initialize context memory (shared + user-specific)
5. Check for demo triggers or active demo state
6. Prepare messages with system prompt containing memory contexts
7. Call Azure OpenAI with function definitions (agent metadata)
8. If function called: execute agent → add result to conversation → get final response
9. Parse response into formatted + voice parts
10. Return JSON: `{"assistant_response": "...", "voice_response": "...", "agent_logs": "...", "user_guid": "..."}`

**Power Platform Mode (Teams/M365 Copilot):**
1. User message in Teams/M365 Copilot → Copilot Studio
2. Copilot Studio processes intent → triggers Power Automate flow
3. Power Automate enriches with user context (Office 365 profile)
4. HTTP POST to Azure Function with user context
5. Azure Function processes (steps 2-10 from above)
6. Response returns to Power Automate
7. Power Automate formats response for Copilot Studio
8. Copilot Studio displays in Teams/M365 Copilot chat
9. User sees formatted response with agent actions

**Data Flow Diagram:**
```
[User] ─────→ [Copilot Studio] ─────→ [Power Automate] ─────→ [Azure Function]
   ↑                                                                    │
   │                                                                    ↓
   │                                                          [Azure OpenAI]
   │                                                                    │
   │                                                                    ↓
   │                                                             [Agent Layer]
   │                                                                    │
   │                                                                    ↓
   └──────────← [Copilot Studio] ←──────── [Power Automate] ←── [Response]
```

### Key Design Patterns

**String Safety:**
- All message content sanitized via `ensure_string_content()` to prevent None/undefined errors (function_app.py:21-50)
- Function arguments stringified via `ensure_string_function_args()` (function_app.py:52-70)
- Default values for all potentially None values

**CORS Handling:**
- All responses include CORS headers via `build_cors_response()` (function_app.py:72-83)
- OPTIONS preflight requests supported

**Error Handling:**
- Retry logic (max 3 attempts) for OpenAI API calls (function_app.py:566, retry_count)
- Agent loading failures logged but don't crash the app (function_app.py:100, 158)
- Graceful degradation when memory initialization fails (function_app.py:298-301)

**Agent Loading Strategy:**
- Local `agents/` folder loaded first
- Azure File Storage `agents/` share loaded next (overlays local)
- Azure File Storage `multi_agents/` share loaded last
- Files written to `/tmp/agents` and `/tmp/multi_agents` for module loading
- Per-user agent filtering applied if `enabled_agents.json` exists
- Manifest-based loading optimized for performance

## Configuration

### Environment Variables (local.settings.json)

Required settings:
- `AZURE_OPENAI_API_KEY`: Azure OpenAI service key
- `AZURE_OPENAI_ENDPOINT`: Azure OpenAI endpoint URL (e.g., "https://your-resource.openai.azure.com/")
- `AZURE_OPENAI_DEPLOYMENT_NAME`: Model deployment name (e.g., "gpt-4o", "gpt-5-chat")
- `AZURE_OPENAI_API_VERSION`: API version (e.g., "2025-01-01-preview")
- `AzureWebJobsStorage`: Azure Storage connection string for file shares
- `AZURE_FILES_SHARE_NAME`: Name of the Azure File Share (unique per deployment)
- `ASSISTANT_NAME`: Digital Twin identity name (default: "Digital Twin") - Used in system prompt
- `CHARACTERISTIC_DESCRIPTION`: Digital Twin personality and capabilities (default: "Your personalized AI digital twin that learns from you, maintains persistent memory of your context and preferences, and evolves to serve as your intelligent counterpart across all interactions") - Used in system prompt

**Example local.settings.json structure:**
```json
{
  "IsEncrypted": false,
  "Values": {
    "AzureWebJobsStorage": "DefaultEndpointsProtocol=https;AccountName=...",
    "FUNCTIONS_WORKER_RUNTIME": "python",
    "AZURE_OPENAI_API_KEY": "your-openai-api-key",
    "AZURE_OPENAI_ENDPOINT": "https://your-resource.openai.azure.com/",
    "AZURE_OPENAI_DEPLOYMENT_NAME": "gpt-4o",
    "AZURE_OPENAI_API_VERSION": "2025-01-01-preview",
    "AZURE_FILES_SHARE_NAME": "your-unique-share-name",
    "ASSISTANT_NAME": "Digital Twin",
    "CHARACTERISTIC_DESCRIPTION": "Your personalized AI digital twin that learns from you, maintains persistent memory of your context and preferences, and evolves to serve as your intelligent counterpart across all interactions"
  }
}
```

**Note:** The setup scripts automatically generate this file with proper values from your Azure deployment.

### Web Interface

`index.html` provides a full-featured chat UI with:
- Multi-user support (GUID-based sessions)
- Voice synthesis for voice responses
- Markdown rendering with syntax highlighting
- Code block copy functionality
- Mobile-responsive design

## Adding Custom Agents

Create a new file in `agents/` folder:

```python
from agents.basic_agent import BasicAgent

class MyCustomAgent(BasicAgent):
    def __init__(self):
        self.name = 'MyCustom'
        self.metadata = {
            "name": self.name,
            "description": "What this agent does",
            "parameters": {
                "type": "object",
                "properties": {
                    "input": {
                        "type": "string",
                        "description": "Input parameter"
                    }
                },
                "required": ["input"]
            }
        }
        super().__init__(self.name, self.metadata)

    def perform(self, **kwargs):
        input_data = kwargs.get('input', '')
        # Your logic here
        return f"Processed: {input_data}"
```

Agents are automatically loaded on function startup. To access Azure storage or other services, import `AzureFileStorageManager` from `utils.azure_file_storage`.

**Uploading Custom Agents to Azure Storage:**
```python
from utils.azure_file_storage import AzureFileStorageManager

storage = AzureFileStorageManager()

# Upload to agents/ share
with open('my_custom_agent.py', 'r') as f:
    agent_code = f.read()
    storage.write_file('agents', 'my_custom_agent.py', agent_code)

# Upload to multi_agents/ share (for coordinated agents)
storage.write_file('multi_agents', 'orchestrator_agent.py', orchestrator_code)
```

**Enabling Agents Per User:**
```python
import json

# Create agent filter for a specific user
enabled_agents = ["context_memory_agent.py", "my_custom_agent.py"]
config = json.dumps(enabled_agents)

storage.write_file('agent_config/USER_GUID', 'enabled_agents.json', config)
```

## Deployment

The project uses Azure Resource Manager (ARM) template deployment:
- Template: `azuredeploy.json`
- Deploy script: `deploy.sh`
- Post-deployment setup scripts auto-generated with embedded credentials

Deployment provisions:
- Azure Function App (Consumption plan)
- Azure OpenAI Service
- Azure Storage Account (for file shares and function state)
- Application Insights (optional monitoring)

## Power Platform Integration (Optional)

### Overview

Deploy your AI agents directly into Microsoft Teams and Microsoft 365 Copilot using the pre-configured Power Platform solution. This integration enables:
- Native Teams chat bot experience
- M365 Copilot declarative agent deployment
- User context from Office 365 (email, calendar, OneDrive)
- Enterprise-grade authentication and compliance
- No-code configuration through Copilot Studio

### Prerequisites

**Required Licenses:**
- Power Platform license (or trial)
- Copilot Studio license (for M365 integration)
- Microsoft 365 license (for Teams and M365 Copilot)

**Technical Requirements:**
- Azure Function must be accessible from Power Platform (public endpoint or VNet integration)
- Admin consent may be required for M365 Copilot deployment
- Function key for authentication

### Quick Setup Guide

#### 1. Download Power Platform Solution

Download the pre-configured solution package:
- File: `MSFTAIBASMultiAgentCopilot_1_0_0_2.zip`
- Location: [GitHub Releases](https://github.com/kody-w/AI-Agent-Templates/raw/main/MSFTAIBASMultiAgentCopilot_1_0_0_2.zip)

#### 2. Import Solution to Power Platform

1. Navigate to [make.powerapps.com](https://make.powerapps.com)
2. Go to **Solutions** → **Import solution**
3. Upload the downloaded ZIP file
4. Click **Next** → **Import**
5. Wait for import to complete (2-5 minutes)

#### 3. Configure Power Automate Connection

The solution includes a Power Automate flow that connects Copilot Studio to your Azure Function:

1. Open the imported solution
2. Find the flow: **"Talk to MAC (Migration Assessment Copilot)"**
3. Edit the flow and locate the HTTP action
4. Update the HTTP action configuration:
   ```
   URL: [Your Azure Function URL from deployment]
   Headers:
     - x-functions-key: [Your Function Key]
   Method: POST
   Body: Dynamic content from trigger
   ```
5. **Save** and **Turn on** the flow

**Finding Your Function URL:**
- Azure Portal → Function App → Functions → `businessinsightbot_function` → Get Function URL
- Format: `https://<your-function-app>.azurewebsites.net/api/businessinsightbot_function`

**Finding Your Function Key:**
- Azure Portal → Function App → Functions → `businessinsightbot_function` → Function Keys → Copy default key

#### 4. Configure Copilot Studio Bot

1. Navigate to [Copilot Studio](https://copilotstudio.microsoft.com)
2. Find your imported bot: **"Agent"**
3. Open **Topics** → **MAIN** topic
4. Verify the Power Automate action is connected to your flow
5. Test the bot in the **Test** pane (right side)
   - Try: "Hello" to verify basic connectivity
   - Try: "What can you do?" to test agent routing

#### 5. Deploy to Microsoft Teams

**Teams Deployment:**
1. In Copilot Studio, go to **Channels**
2. Select **Microsoft Teams**
3. Click **Turn on Teams**
4. Click **Open bot** to test in Teams
5. Share bot with users via Teams Admin Center (if required)

**Microsoft 365 Copilot Deployment:**
1. In Copilot Studio, enable **Microsoft 365 Copilot** channel
2. Configure declarative agent settings:
   - Name: Your bot name
   - Description: What your bot does
   - Instructions: How users should interact
   - Capabilities: Select relevant actions
3. **Submit for admin approval** (if required by your organization)
4. Once approved, users can @mention your bot in M365 Copilot

### Power Automate Flow Details

**Flow Name:** RAPP Backend Connector

**Trigger:** When Copilot Studio calls the flow
- Receives user input and conversation context
- Passes Office 365 user information (if using Power Platform integration)

**Actions:**
1. **Initialize Variables** - Set up conversation tracking
2. **HTTP Request** - Call Azure Function with:
   ```json
   {
     "user_input": "User's message",
     "conversation_history": [],
     "user_guid": "Office 365 user ID"
   }
   ```
3. **Parse JSON** - Process Azure Function response
4. **Return to Copilot Studio** - Send formatted response

**Error Handling:**
- Retry logic for transient failures
- Fallback messages for API errors
- Logging to Power Automate run history

### Copilot Studio Topics

**MAIN Topic:**
- Handles all user messages
- Routes to Power Automate flow
- Displays agent responses
- Manages conversation context

**Escalation Topic:**
- Transfers to human agent (if configured)
- Captures feedback
- Logs unhandled scenarios

**Fallback Topic:**
- Catches unrecognized intents
- Provides helpful suggestions
- Maintains conversation flow

### User Context Integration

When deployed via Power Platform, your agents automatically receive:

**User Information:**
- Display Name
- Email Address
- Office 365 User ID
- Department/Title (if available)

**Usage Example in Agent:**
```python
class PersonalizedAgent(BasicAgent):
    def perform(self, user_context=None, **kwargs):
        user_email = user_context.get('email', 'Unknown')
        user_name = user_context.get('name', 'User')

        return f"Hello {user_name}, I have your context from {user_email}"
```

### Monitoring and Troubleshooting

**Power Automate:**
- View run history in Power Automate portal
- Check for failed runs and error messages
- Review input/output for each action

**Copilot Studio:**
- Use Analytics dashboard for usage metrics
- Review conversation transcripts
- Monitor topic performance

**Azure Function:**
- Application Insights for detailed logs
- Function Monitor for execution history
- Log Stream for real-time debugging

**Common Issues:**

1. **401 Unauthorized Error**
   - Verify Function Key is correct
   - Check Function App authentication settings
   - Ensure CORS is configured properly

2. **Flow Fails to Execute**
   - Verify flow is turned ON
   - Check connections are authenticated
   - Review flow run history for errors

3. **Bot Doesn't Respond**
   - Test flow independently first
   - Verify Copilot Studio topic is published
   - Check Power Automate action is connected

4. **Slow Response Times**
   - Review Azure Function performance metrics
   - Check Power Automate execution time
   - Consider scaling Function App plan

### Cost Considerations

**Power Platform:**
- ~$20/user/month for Power Apps + Copilot Studio
- Included in some Microsoft 365 E3/E5 licenses
- Trial available for development

**Azure Resources:**
- Function App: ~$5-10/month (Consumption plan)
- OpenAI: ~$0.01 per 1K tokens
- Storage: <$1/month for typical usage

**Total Estimated Cost:** $25-40/user/month for full integration

### Security Best Practices

1. **Never expose Function Keys in client code**
2. **Use Managed Identity** for Azure resource authentication
3. **Enable Application Insights** for audit logging
4. **Implement rate limiting** in Azure Function
5. **Review Copilot Studio security settings** regularly
6. **Follow Microsoft 365 DLP policies**

### Advanced Scenarios

**Multi-Environment Setup:**
- Dev: Separate Function App + Copilot Studio environment
- Staging: Pre-production testing with test users
- Production: Full deployment with monitoring

**Custom Authentication:**
- Implement Azure AD authentication in Function App
- Use Power Automate premium connectors
- Configure custom claims in Copilot Studio

**Hybrid Deployment:**
- Power Platform for Teams/M365 Copilot
- Direct API for web applications
- Shared Azure Function backend

## Important Notes

- **Never commit `local.settings.json`** - contains secrets
- **Python 3.11 required** - Python 3.13+ causes Azure Functions compatibility issues
- **Agent files from Azure Storage** are loaded into `/tmp/agents` and `/tmp/multi_agents` at runtime
- **Default GUID** (`c0p110t0-aaaa-bbbb-cccc-123456789abc`) is used when no user GUID provided
- **Response format** must include `|||VOICE|||` delimiter for proper voice/formatted response splitting
- **Memory context** automatically switches based on user GUID in request
- **Power Platform integration** is optional - RAPP works standalone via REST API as primary pattern
- **Function keys should be rotated** regularly for security
- **Monitor API usage** to avoid unexpected costs
- **RAPP is platform-agnostic** - while examples show Azure deployment, the pattern works on any cloud platform
- **Agent manifest system** (`agent_manifest.json`) caches agent metadata for faster loading - regenerate when adding new agents

## Utilities

**AzureFileStorageManager** (`utils/azure_file_storage.py`):
- Core utility for reading/writing files to Azure File Storage
- Methods: `read_file(directory, filename)`, `write_file(directory, filename, content)`, `list_files(directory)`
- Handles connection strings, retries, and error handling
- Supports both text and binary file operations
- Memory context management via `set_memory_context(guid)` method
- SAS token generation for temporary download URLs via `generate_download_url()`

## Common Development Patterns

**Testing a new agent locally:**
1. Create agent file in `agents/` folder (e.g., `my_test_agent.py`)
2. Restart the function: `func start` (or `./run.sh` / `.\run.ps1`)
3. Test via API call with test user GUID
4. Check logs for agent loading confirmation

**Debugging agent execution:**
```python
# Add logging in your agent's perform method
import logging

class MyAgent(BasicAgent):
    def perform(self, **kwargs):
        logging.info(f"MyAgent called with: {kwargs}")
        result = "some result"
        logging.info(f"MyAgent returning: {result}")
        return result
```

**Working with memory:**
```python
# Read current memory
storage = AzureFileStorageManager()
storage.set_memory_context(user_guid)  # Set context for specific user
user_memory = storage.read_json()  # Reads from user's memory file

# Write to memory
storage.set_memory_context(user_guid)
memory_data = {"facts": ["User prefers dark mode"], "preferences": {}}
storage.write_json(memory_data)
```

**Creating a demo/scripted conversation:**
```python
# Upload demo JSON to Azure Storage demos/ directory
demo_data = {
    "trigger_phrases": ["start demo", "show me a demo"],
    "conversation_flow": [
        {
            "step": 1,
            "user_input_pattern": ".*",
            "canned_response": "Welcome to the demo! Let me show you around..."
        },
        {
            "step": 2,
            "user_input_pattern": ".*",
            "canned_response": "Here's the next step..."
        }
    ]
}

storage = AzureFileStorageManager()
storage.write_file('demos', 'my_demo.json', json.dumps(demo_data))
```
